# ì‹œì‘í•˜ê¸° ì „, "streamlit run team_project.py"
# ì°¸ê³ ìë£Œ
# * API Document: https://docs.streamlit.io/library/api-reference
# * Examples: https://github.com/MarcSkovMadsen/awesome-streamlit

#ëª¨ë“ˆë¶ˆëŸ¬ì˜¤ê¸°
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sb
import tensorflow
import sklearn
from PIL import Image
import pyLDAvis
import pyLDAvis.gensim_models
import seaborn as sns

#ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
c_a = pd.read_excel("chosun_contents.xlsx")
c_c = pd.read_excel("chosun_comments.xlsx")
j_a = pd.read_excel("joongang_contents.xlsx")
j_c = pd.read_excel("joongang_comments.xlsx")
h_a = pd.read_excel("hani_contents.xlsx")
h_c = pd.read_excel("hani_comments.xlsx")
k_a = pd.read_excel("kyunghyang_contents.xlsx")
k_c_np = pd.read_excel("kyunghyang_nonpolitics_comments.xlsx")
k_c_p = pd.read_excel("kyunghyang_politics_comments.xlsx")
moral_result = pd.read_excel("moral_result.xlsx", index_col= 0)


# ë°ì´í„° í´ë¦¬ë‹
r_a = []
for i in c_a.iloc:
    r_a.append(i[0])
for i in j_a.iloc:
    r_a.append(i[0])

l_a = []
for i in h_a.iloc:
    l_a.append(i[0])
for i in k_a.iloc:
    l_a.append(i[0])
    
    
r_c = []
for i in c_c.iloc:
    for j in i:
        if type(j) == str:
            r_c.append(j)
for i in j_c.iloc:
    for j in i:
        if type(j) == str:
            r_c.append(j)

l_c = []
for i in h_c.iloc:
    for j in i:
        if type(j) == str:
            l_c.append(j)
for i in k_c_np.iloc:
    for j in i:
        if type(j) == str:
            l_c.append(j)
for i in k_c_p.iloc:
    for j in i:
        if type(j) == str:
            l_c.append(j)    

#ì²­ë¬¸íšŒ ë°ì´í„°
f = open("hearing.txt", encoding = 'utf-8')
lines = f.readlines()
sep = []
for i in lines:
    sep.append(i.split("\t"))

dp = []
pp = []
han = []
for i in sep:
    if i[0] == "ë”ë¶ˆì–´ë¯¼ì£¼ë‹¹":
        dp.append(i[3])
    elif i[0] == "êµ­ë¯¼ì˜í˜":
        pp.append(i[3])
    elif i[2] == "í•œë™í›ˆ":
        han.append(i[3])
        
# ë°ì´í„° í•©ì¹˜ê¸°
r_a_str = ' '.join(r_a)
l_a_str = ' '.join(l_a)
r_c_str = ' '.join(r_c)
l_c_str = ' '.join(l_c)
ë¯¼ì£¼ë‹¹ë°œì–¸ = ' '.join(dp)
êµ­ë¯¼ì˜í˜ë°œì–¸ = ' '.join(pp)
í•œë™í›ˆë°œì–¸ = ' '.join(han)

# ì½”ì‚¬ì¸ìœ ì‚¬ë„
def cos_sim(text1, text2):
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.metrics.pairwise import cosine_similarity
    tv = TfidfVectorizer()
    sents = (text1, text2)
    tfidf_matrix = tv.fit_transform(sents)
    st.write(cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2]))

# í˜•íƒœì†Œë¶„ì„
from konlpy.tag import Komoran
tagger = Komoran()
from collections import Counter
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import numpy as np
import networkx as nx 

stop_words = ['DB','ë‹¤ìŒ', 'ìœ„ì›ì¥', 'ìœ„ì›', 'ì˜ì›', 'ê°„ì‚¬', 'êµ­íšŒ','PPT', 'ì ê¹', 'ì ê¹ë§Œ', 'ì ê¹ë§Œìš”', 'í›„ë³´ì', 'ì²­ë¬¸', 'ì²­ë¬¸íšŒ', 'ì¸ì‚¬ì²­ë¬¸íšŒ', 'ìœ„ì›íšŒ','ë²•ë¬´ë¶€', 'ì¥ê´€', 'í•œë™í›ˆ', 'ìµœê·¼','ì˜¤í›„','ì˜¤ì „','ì˜¤ëŠ˜','ì´ë‚ ','ì´í›„','ê·¸ê²ƒ','ê·¸ë•Œ','ì§€ê¸ˆ','ë‹¹ì¥','ë‹¹ì‹œ','ì´ë²ˆ','ì´ì œ','ì´ê±´','ì´ê²ƒ','ì´ê±°','ì—¬ê¸°','ê±°ê¸°','ê²½ìš°','ì •ë„','ì–´ë””','ì €í¬','ì œê°€','ì €ê²ƒ','ìš°ë¦¬', 'ì§„í–‰', 'ì§ˆì˜', 'í˜‘ì˜', 'í•©ì˜','íšŒì˜','ì •íšŒ','ì˜ê²°','ìë£Œ','ê´€ë ¨','ì–˜ê¸°','ë§ì”€','ë°œì–¸','ìƒê°','ìœ„ì›','ë¬¸ì œ','ì§ˆë¬¸','ë‹µë³€','ì •íšŒ','ì´ìƒ','ì´ì œ','ì´ë‹¤','ìˆë‹¤','ì—¬ëŸ¬ë¶„','ì—°í•©ë‰´ìŠ¤','ë‰´ìŠ¤1','ê²½í–¥ì‹ ë¬¸','í•œê²¨ë ˆ','!!!','!!','ë¼ê³ ','ë³´ë‹ˆ','ë™ì•ˆ','ìš”ì¦˜','ìµœê³ ','ì œì¼','ë‹ˆë“¤','ë„ˆí¬','ë¶€ë¶„','ë‚´ìš©','ë³¸ì¸','ìì‹ ','ìê¸°','ë“œë¦´','ë§Œì•½','\n','\t','\r','â™¥' ,'Î±' , 'â– ','â–¶','â–²','/','+' ,'-','*','"',',','(',')','â—‹',':','?','!!','!!!','!','.','[',']','â€¦']

# ë°ì´í„° ì „ì²˜ë¦¬
import re 

RE_EMOJI=re.compile('[\U00010000-\U0010ffff]', flags=re.UNICODE)

def strip_emoji(text):
    return RE_EMOJI.sub(r'', text)

SW=['DB','ë‹¤ìŒ', 'ìœ„ì›ì¥', 'ìœ„ì›', 'ì˜ì›', 'PPT', 'ì˜ˆ', 'ì ê¹', 'ì ê¹ë§Œ', 'ì ê¹ë§Œìš”', 'í›„ë³´ì', 'ì²­ë¬¸','ì²­ë¬¸íšŒ', 'ì¸ì‚¬ì²­ë¬¸íšŒ', 'ë²•ë¬´ë¶€', 'ì¥ê´€', 'í•œë™í›ˆ', 'ì˜¤í›„', 'ì´ë‚ ', 'ë§ì”€', 'ê·¸ê²ƒ', 'ì œê°€','ìš°ë¦¬', 'ì§„í–‰', 'ì§ˆì˜', 'í•©ì˜','ì •íšŒ','ìë£Œ','ê´€ë ¨','ì–˜ê¸°','ìƒê°','\n','\t','\r','â™¥' ,'Î±' , 'â– ','â–¶','â–²','/','+' ,'-','*','"',',','(',')','â—‹',':','?','!!','!!!','!','.','[',']','â€¦']

# @st.cache
# def get_noun(texts):
#     tagged_texts = []
#     for text in texts:
#         try:
#             tagged_texts.append(tagger.pos(text))
#         except:
#             pass
        
#     new_list = []
#     for i in tagged_texts:
#         for word, tag in i:
#             if tag in ["NNG", "NNP", "NP"]:
#                 new_list.append(word)
#             #elif tag in ["VV", "VA"]:
#                 #new_list.append(word+"ë‹¤")
    
#     return(new_list)
                
# #ëª…ì‚¬ë­‰ì¹˜
# r_a_noun = get_noun(r_a)
# r_c_noun = get_noun(r_c)
# l_a_noun = get_noun(l_a)
# l_c_noun = get_noun(l_c)
# dp_noun = get_noun(dp)
# pp_noun = get_noun(pp)
# han_noun = get_noun(han)

# # í•„í„°ë§
# def filtering(noun_list):
#     filtered_list = []
#     for i in noun_list:
#         if i not in SW and len(i)>1:
#             filtered_list.append(i)
#     filtered_list = [strip_emoji(s) for s in filtered_list]
#     filtered_list = [t.replace('ìˆ˜ì™„','ê²€ìˆ˜ì™„ë°•').replace('ë‚¨êµ­','ê¹€ë‚¨êµ­').replace('ê¹€ê²½', 'ê¹€ê²½ìœ¨').replace('ìµœê°•', 'ìµœê°•ìš±') for t in filtered_list]
    
#     return(filtered_list)

# r_a_filtered = filtering(r_a_noun)
# r_c_filtered = filtering(r_c_noun)
# l_a_filtered = filtering(l_a_noun)
# l_c_filtered = filtering(l_c_noun)
# dp_filtered = filtering(dp_noun)
# pp_filtered = filtering(pp_noun)
# han_filtered = filtering(han_noun)

# chunks
# r_a_chunks = [r_a_filtered[x:x+100] for x in range(0, len(r_a_filtered), 100)]
# r_c_chunks = [r_c_filtered[x:x+100] for x in range(0, len(r_c_filtered), 100)]
# l_a_chunks = [l_a_filtered[x:x+100] for x in range(0, len(l_a_filtered), 100)]
# l_c_chunks = [l_c_filtered[x:x+100] for x in range(0, len(l_c_filtered), 100)]
# dp_chunks = [dp_filtered[x:x+100] for x in range(0, len(dp_filtered), 100)]
# pp_chunks = [pp_filtered[x:x+100] for x in range(0, len(pp_filtered), 100)]
# han_chunks = [han_filtered[x:x+100] for x in range(0, len(han_filtered), 100)]

#í† í”½ëª¨ë¸ë§ ë¶„ì„ì‹œì‘
# from gensim import corpora 
# from gensim import models
# from gensim.models import word2vec
# from gensim.models import LdaModel

# r_a_dictionary = corpora.Dictionary(r_a_chunks)
# r_a_corpus = [r_a_dictionary.doc2bow(text) for text in r_a_chunks] 

# r_c_dictionary = corpora.Dictionary(r_c_chunks)
# r_c_corpus = [r_c_dictionary.doc2bow(text) for text in r_c_chunks] 

# l_a_dictionary = corpora.Dictionary(l_a_chunks)
# l_a_corpus = [l_a_dictionary.doc2bow(text) for text in l_a_chunks] 

# l_c_dictionary = corpora.Dictionary(l_c_chunks)
# l_c_corpus = [l_c_dictionary.doc2bow(text) for text in l_c_chunks] 

# dp_dictionary = corpora.Dictionary(dp_chunks)
# dp_corpus = [dp_dictionary.doc2bow(text) for text in dp_chunks] 

# pp_dictionary = corpora.Dictionary(pp_chunks)
# pp_corpus = [pp_dictionary.doc2bow(text) for text in pp_chunks] 

# han_dictionary = corpora.Dictionary(han_chunks)
# han_corpus = [han_dictionary.doc2bow(text) for text in han_chunks] 

# #LDA ëª¨ë¸
# r_a_ldamodel =models.ldamodel.LdaModel(r_a_corpus, num_topics=5, id2word=r_a_dictionary, passes=20) #3 
# r_c_ldamodel =models.ldamodel.LdaModel(r_c_corpus, num_topics=6, id2word=r_c_dictionary, passes=20) #3
# l_a_ldamodel =models.ldamodel.LdaModel(l_a_corpus, num_topics=6, id2word=l_a_dictionary, passes=20) #7
# l_c_ldamodel =models.ldamodel.LdaModel(l_c_corpus, num_topics=7, id2word=l_c_dictionary, passes=20) #8
# dp_ldamodel =models.ldamodel.LdaModel(dp_corpus, num_topics=7, id2word=dp_dictionary, passes=20) #9
# pp_ldamodel =models.ldamodel.LdaModel(pp_corpus, num_topics=4, id2word=pp_dictionary, passes=20) #9
# han_ldamodel =models.ldamodel.LdaModel(han_corpus, num_topics=8, id2word=han_dictionary, passes=20) #7

# # perplexity
# import matplotlib.pyplot as plt

# @st.cache
# def perplexity_value(dictionary, corpus, ldamodel):
#     perplexity = []
#     for i in range(2,10):
#         ldamodel = models.ldamodel.LdaModel(corpus, num_topics=i, id2word=dictionary, passes=20)
#         perplexity.append(ldamodel.log_perplexity(corpus))
#     return(perplexity)

# r_a_perplexity = perplexity_value(r_a_dictionary, r_a_corpus, r_a_ldamodel)
# r_c_perplexity = perplexity_value(r_c_dictionary, r_c_corpus, r_c_ldamodel)
# l_a_perplexity = perplexity_value(l_a_dictionary, l_a_corpus, l_a_ldamodel)
# l_c_perplexity = perplexity_value(l_c_dictionary, l_c_corpus, l_c_ldamodel)
# dp_perplexity = perplexity_value(dp_dictionary, dp_corpus, dp_ldamodel)
# pp_perplexity = perplexity_value(pp_dictionary, pp_corpus, pp_ldamodel)
# han_perplexity = perplexity_value(han_dictionary, han_corpus, han_ldamodel)

# # coherence
# import matplotlib.pyplot as plt
# from gensim.models import CoherenceModel

# r_a_coherence = []
# for i in range(2, 10):
#     r_a_ldamodel = models.ldamodel.LdaModel(r_a_corpus, num_topics=i, id2word=r_a_dictionary, passes=20)
#     coherence_model_lda = CoherenceModel(model=r_a_ldamodel, texts=r_a_chunks, dictionary=r_a_dictionary, topn=10)
#     coherence_lda = coherence_model_lda.get_coherence()
#     r_a_coherence.append(coherence_lda)

# r_c_coherence = []
# for i in range(2, 10):
#     r_c_ldamodel = models.ldamodel.LdaModel(r_c_corpus, num_topics=i, id2word=r_c_dictionary, passes=20)
#     coherence_model_lda = CoherenceModel(model=r_c_ldamodel, texts=r_c_chunks, dictionary=r_c_dictionary, topn=10)
#     coherence_lda = coherence_model_lda.get_coherence()
#     r_c_coherence.append(coherence_lda)
    
# l_a_coherence = []
# for i in range(2, 10):
#     l_a_ldamodel = models.ldamodel.LdaModel(l_a_corpus, num_topics=i, id2word=l_a_dictionary, passes=20)
#     coherence_model_lda = CoherenceModel(model=l_a_ldamodel, texts=l_a_chunks, dictionary=l_a_dictionary, topn=10)
#     coherence_lda = coherence_model_lda.get_coherence()
#     l_a_coherence.append(coherence_lda)
    
# l_c_coherence = []
# for i in range(2, 10):
#     l_c_ldamodel = models.ldamodel.LdaModel(l_c_corpus, num_topics=i, id2word=l_c_dictionary, passes=20)
#     coherence_model_lda = CoherenceModel(model=l_c_ldamodel, texts=l_c_chunks, dictionary=l_c_dictionary, topn=10)
#     coherence_lda = coherence_model_lda.get_coherence()
#     l_c_coherence.append(coherence_lda)
    
# dp_coherence = []
# for i in range(2, 10):
#     dp_ldamodel = models.ldamodel.LdaModel(dp_corpus, num_topics=i, id2word=dp_dictionary, passes=20)
#     coherence_model_lda = CoherenceModel(model=dp_ldamodel, texts=dp_chunks, dictionary=dp_dictionary, topn=10)
#     coherence_lda = coherence_model_lda.get_coherence()
#     dp_coherence.append(coherence_lda)
    
# pp_coherence = []
# for i in range(2, 10):
#     pp_ldamodel = models.ldamodel.LdaModel(pp_corpus, num_topics=i, id2word=pp_dictionary, passes=20)
#     coherence_model_lda = CoherenceModel(model=pp_ldamodel, texts=pp_chunks, dictionary=pp_dictionary, topn=10)
#     coherence_lda = coherence_model_lda.get_coherence()
#     pp_coherence.append(coherence_lda)

# han_coherence = []
# for i in range(2, 10):
#     han_ldamodel = models.ldamodel.LdaModel(han_corpus, num_topics=i, id2word=han_dictionary, passes=20)
#     coherence_model_lda = CoherenceModel(model=han_ldamodel, texts=han_chunks, dictionary=han_dictionary, topn=10)
#     coherence_lda = coherence_model_lda.get_coherence()
#     han_coherence.append(coherence_lda)

# ë„¤íŠ¸ì›Œí¬ ë¶„ì„ í•¨ìˆ˜
def net(texts, co_oc):
    from IPython.display import display, HTML
    from pyvis import network as net
    tagged_texts = []
    for text in texts:
        try:
            tagged_texts.append(tagger.pos(text))
        except:
            pass
    new_list = []
    for i in tagged_texts:
        for word, tag in i:
            if tag in ["NNG", "NNP","NP"] and len(word) > 1 and word not in stop_words:
                new_list.append(word)
#             elif tag in ["VV", "VA"]:
#                 new_list.append(word+"ë‹¤")
    new_list = [t.replace('ìˆ˜ì™„','ê²€ìˆ˜ì™„ë°•').replace('ë‚¨êµ­','ê¹€ë‚¨êµ­').replace('ê¹€ê²½', 'ê¹€ê²½ìœ¨').replace('ê¹€ê²½ìœ¨ë¥ ', 'ê¹€ê²½ìœ¨').replace('ìµœê°•', 'ìµœê°•ìš±').replace('ì†¡ê¸°','ì†¡ê¸°í—Œ').replace('ê´‘ìš°','ê´‘ìš°ë³‘').replace('ì„ ì¸','ë‹¹ì„ ì¸').replace('ê¸°ë“', 'ê¸°ë“ê¶Œ').replace('ì‚¬ê¶Œ','ìˆ˜ì‚¬ê¶Œ').replace('ë²•ì œì‚¬','ë²•ì‚¬ìœ„').replace('êµ¬ì²´','êµ¬ì²´ì ').replace('ì›ë‚´','ì›ë‚´ëŒ€í‘œ').replace('ë²•ë¬´','ë²•ë¬´ë¶€') for t in new_list]
    unique_words = set(new_list)
    unique_words = list(unique_words)
    word_index = {word: i for i, word in enumerate(unique_words)}
    occurs = np.zeros([len(tagged_texts), len(unique_words)])

    for i, sent in enumerate(tagged_texts):
        sub_list = []
        for word, tag in sent:
            if tag in ["NNG", "NNP","NP"] and len(word) > 1 and word not in stop_words:
                sub_list.append(word)
        sub_list = [t.replace('ìˆ˜ì™„','ê²€ìˆ˜ì™„ë°•').replace('ë‚¨êµ­','ê¹€ë‚¨êµ­').replace('ê¹€ê²½', 'ê¹€ê²½ìœ¨').replace('ê¹€ê²½ìœ¨ë¥ ', 'ê¹€ê²½ìœ¨').replace('ìµœê°•', 'ìµœê°•ìš±').replace('ì†¡ê¸°','ì†¡ê¸°í—Œ').replace('ê´‘ìš°','ê´‘ìš°ë³‘').replace('ì„ ì¸','ë‹¹ì„ ì¸').replace('ê¸°ë“', 'ê¸°ë“ê¶Œ').replace('ì‚¬ê¶Œ','ìˆ˜ì‚¬ê¶Œ').replace('ë²•ì œì‚¬','ë²•ì‚¬ìœ„').replace('êµ¬ì²´','êµ¬ì²´ì ').replace('ì›ë‚´','ì›ë‚´ëŒ€í‘œ').replace('ë²•ë¬´','ë²•ë¬´ë¶€') for t in sub_list]
        for sub in sub_list:
            index = word_index[sub]
            occurs[i][index] = 1
#             elif tag in ["VV", "VA"]:
#                 index = word_index[word+"ë‹¤"]
#                occurs[i][index] = 1
    co_occurs = occurs.T.dot(occurs)
    graph = net.Network(height='1000px', width='50%',heading='')
    graph.set_options("""
    const options = {
      "nodes": {
       "borderWidth": null,
       "borderWidthSelected": 4,
       "opacity": 1,
       "font": {
         "size": 15,
         "strokeWidth": 7
       },
       "size": 16
      },
      "edges": {
        "hoverWidth": 1.1,
        "physics": false,
        "scaling": {
          "min": 6,
          "max": 20,
              "label": {
                "min": null,
                "max": null,
                "maxVisible": 50,
                "drawThreshold": null
              }
        },
        "selectionWidth": 1.8,
        "selfReferenceSize": 28,
        "selfReference": {
          "size": 28,
          "angle": 1.5707963267949
        },
        "smooth": false
      }
    }""")
#    graph.show_buttons(filter_=['physics'])
#    graph.show_buttons(filter_=['nodes'])
#    graph.show_buttons(filter_=['edges'])
    for i in range(len(unique_words)):
        for j in range(i + 1, len(unique_words)):
            if co_occurs[i][j] > co_oc:
                graph.add_node(unique_words[i])
                graph.add_node(unique_words[j])
                graph.add_edge(unique_words[i], unique_words[j])
    
    graph.show('example.html')
    display(HTML('example.html'))


# ë„ë•ê¸°ë°˜ì‚¬ì „ - í˜•íƒœì†Œë¡œ í…ìŠ¤íŠ¸ ìª¼ê°œê¸° í•¨ìˆ˜
@st.cache
def get_words(texts):
    tagged_texts = []
    for text in texts:
        try:
            tagged_texts.append(tagger.pos(text))
        except:
            pass
        
#     new_list = []
#     for i in tagged_texts:
#         for word, tag in i:
#             if tag in ["IC", "MAG", "MAJ", "MM", "NN", "NP", "NR", "VA", "VV", "VX", "XR"]:
#                 new_list.append(i)
    
    return(tagged_texts)


r_a_words = get_words(r_a) #ë³´ìˆ˜ê¸°ì‚¬
r_c_words = get_words(r_c) #ë³´ìˆ˜ëŒ“ê¸€
l_a_words = get_words(l_a) #ì§„ë³´ê¸°ì‚¬
l_c_words = get_words(l_c) #ì§„ë³´ëŒ“ê¸€
dp_words = get_words(dp)
pp_words = get_words(pp)
han_words = get_words(han)

#ë„ë•ê¸°ë°˜ì‚¬ì „
import csv
file = open("lex.csv", encoding = "utf-8")
moral = csv.reader(file)
rows = []
for row in moral:
    rows.append(row)

# 1ì´ ë‹¨ì–´, 4ê°€ moral 1, 13ì´ moral 10
# True, Falseë¡œ êµ¬ë¶„í•´ë†“ì€ csv íŒŒì¼ ë¶ˆëŸ¬ë‹¤ê°€ 10ê°œì˜ ì‚¬ì „ì„ ë”°ë¡œ ë§Œë“  ê²ë‹ˆë‹¤. 
# ë°˜ë³µë¬¸ ëŒë¦¬ê¸° ì‰½ê²Œ í•˜ë ¤ê³  totalì—ë‹¤ê°€ ëª¨ì•„ë’€ìŠµë‹ˆë‹¤.
# total[0]ì€ care ì‚¬ì „, total[1]ì€ harm ì‚¬ì „, ... ì´ëŸ° ì‹ì…ë‹ˆë‹¤. 

care = []
harm = []
fair = []
cheat = []
loyal = []
betray = []
auth = []
subvert = []
sanc = []
dero = []
total = [care, harm, fair, cheat, loyal, betray, auth,subvert, sanc, dero]

for row in rows:
    for i in range(4,14):
        if row[i] == "TRUE":
            total[i-4].append(row[1])
    

@st.cache
def moral_find(data, lexicon) :
    from collections import Counter
    targets = []
    match = []
    outcome = []
    for i in data: #ê°œë³„ ê¸°ì‚¬
        for j in i: #ê°œë³„ íŠœí”Œ ('ë‹¨ì–´', 'í’ˆì‚¬')
            targets.append(j[0])
            
    for i in lexicon:
        res = []
        for word in targets:
            if word in i:
                res.append(word)
        outcome.append(res)
    
    return outcome

r_a_moral = moral_find(r_a_words, total)
r_c_moral = moral_find(r_c_words, total)
l_a_moral = moral_find(l_a_words, total)
l_c_moral = moral_find(l_c_words, total)
dp_moral = moral_find(dp_words, total)
pp_moral = moral_find(pp_words, total)
han_moral = moral_find(han_words, total)

def moral_detail (text, moral_num) :
    st.markdown("ì„ íƒí•˜ì‹  ë„ë•ê¸°ë°˜ì— ì†í•˜ëŠ”")
    st.write("ë‹¨ì–´ ê°œìˆ˜ëŠ” " + str(len(text[moral_num])) + "ê°œ ì…ë‹ˆë‹¤")
    counts= Counter(text[moral_num])
    # print(counts) # ì •í™•íˆ ì–´ë–¤ ë‹¨ì–´ë“¤ì´ ì¡í˜”ëŠ”ì§€ ë³´ë ¤ë©´
    table = pd.DataFrame(columns = ["ë“±ì¥ë‹¨ì–´", "ë“±ì¥íšŸìˆ˜"])
    table["ë“±ì¥ë‹¨ì–´"] = list(counts.keys())
    table["ë“±ì¥íšŸìˆ˜"] = list(counts.values())
    st.dataframe(table.sort_values(by=["ë“±ì¥íšŸìˆ˜"], axis=0, ascending=False)) # ì •í™•íˆ ì–´ë–¤ ë‹¨ì–´ë“¤ì´ ì¡í˜”ëŠ”ì§€ dataframeìœ¼ë¡œ ë³´ì—¬ì¤Œ
    return(table)

# ì œëª©
st.markdown("<h1 style='text-align: center'>TEAM 1</h1>", unsafe_allow_html=True)
st.markdown("<h3 style='text-align: center'>ì¸ì‚¬ì²­ë¬¸íšŒì™€ ì–¸ë¡ ë³´ë„, ëŒ“ê¸€ì— ëŒ€í•œ íƒìƒ‰ì  ì—°êµ¬</h3>", unsafe_allow_html=True)

#ì‚¬ì´ë“œë°”
side = st.sidebar.radio('Result',["INTRO","ì²­ë¬¸íšŒë°ì´í„°","ì–¸ë¡ ë³´ë„", "ëŒ“ê¸€"])
if side == "INTRO" :
    st.header("INTRO")
    st.write("ì¸ì‚¬ì²­ë¬¸íšŒì™€ ê´€ë ¨ëœ ê°œë…ì , ì •ì¹˜í•™ì  ë…¼ì˜")

#ì²­ë¬¸íšŒë°ì´í„° í˜ì´ì§€
elif side == 'ì²­ë¬¸íšŒë°ì´í„°' :
    st.header("ì²­ë¬¸íšŒë°ì´í„°") 
    options = st.multiselect("ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ë³´ê³  ì‹¶ì€ 2ê°€ì§€ë¥¼ ê³ ë¥´ì„¸ìš”", ["ë¯¼ì£¼ë‹¹ë°œì–¸", "í•œë™í›ˆë°œì–¸", "êµ­ë¯¼ì˜í˜ë°œì–¸"])
    d = []
    try : 
        for i in options :
            if i == "ë¯¼ì£¼ë‹¹ë°œì–¸" :
                a = ë¯¼ì£¼ë‹¹ë°œì–¸
                d.append(a)
            elif i == "í•œë™í›ˆë°œì–¸" :
                b = í•œë™í›ˆë°œì–¸
                d.append(b)
            elif i == "êµ­ë¯¼ì˜í˜ë°œì–¸" :
                c = êµ­ë¯¼ì˜í˜ë°œì–¸
                d.append(c)
        cos_sim(d[0], d[1])
    except :
        st.write ("í˜„ì¬", len(options), "ê°œë¥¼ ê³ ë¥´ì…¨ìŠµë‹ˆë‹¤.", " 2ê°œë¥¼ ê³¨ë¼ì£¼ì„¸ìš”")   
    
    st.markdown("***")
    
    col1, col2, col3 = st.columns(3)
    with col1 :
        st.markdown("<h3 style='text-align: center; background-color:blue;'>ë”ë¶ˆì–´ë¯¼ì£¼ë‹¹</h3>", unsafe_allow_html=True)
        
        st.markdown("**ğŸŸ¡ì›Œë“œí´ë¼ìš°ë“œ**")
        st.image("ë¯¼ì£¼ë°œì–¸ wc.png")
        
        st.markdown("**ğŸŸ¡ì–¸ì–´ë„¤íŠ¸ì›Œí¬**")
        st.write("ê³µì¶œí˜„ìˆ˜ì¹˜ 10 ì´ìƒì¸ ë‹¨ì–´ë§Œ í‘œì‹œë©ë‹ˆë‹¤")
        st.write("ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”")
        click = st.button("ë¯¼ì£¼ë‹¹ ì–¸ì–´ë„¤íŠ¸ì›Œí¬")
        if click : net(dp, 10)
        
        # st.markdown("* í† í”½ëª¨ë¸ë§")
        # if st.button('pyLDAvis ë³´ê¸°'):
        #     with st.spinner('Creating pyLDAvis Visualization ...'):
        #         dp_vis = pyLDAvis.gensim_models.prepare(r_a_ldamodel, r_a_corpus, r_a_dictionary, mds='mmds')
        #         py_lda_vis_html = pyLDAvis.prepared_data_to_html(dp_vis)
        
        st.markdown("**ğŸŸ¡ë„ë•ê¸°ë°˜ì‚¬ì „**")
        
        plot_1 = sns.barplot(x= moral_result.index, y=moral_result["ë¯¼ì£¼ë°œì–¸"], data = moral_result)
        plot_1.set_ylabel("ë‹¨ì–´ê°œìˆ˜")
        plot_1.figure.savefig('plot_1.png')
        plt.rcParams['font.family'] = 'NanumGothic'
        st.image("plot_1.png")
               
        selected_moral = st.selectbox('ë¯¼ì£¼ë‹¹ ë„ë•ê¸°ë°˜ ì„ íƒ', ["ë³´ì‚´í•Œ", "ê°€í•´", "ê³µì •", "ë¶€ì •", "ì¶©ì„±", "ë°°ë°˜", "ê¶Œìœ„", "ì „ë³µ", "ìˆœìˆ˜", "íƒ€ë½"])
        moral_dic = {"ë³´ì‚´í•Œ" : 0, "ê°€í•´" : 1, "ê³µì •": 2, "ë¶€ì •": 3 , "ì¶©ì„±":4 , "ë°°ë°˜":5 , "ê¶Œìœ„":6 , "ì „ë³µ":7 , "ìˆœìˆ˜":8 , "íƒ€ë½":9}
        moral_detail(dp_moral, moral_dic["{}".format(str(selected_moral))])


        
        
    with col2 :
        st.markdown("<h3 style='text-align: center; background-color:red;'>êµ­ë¯¼ì˜í˜</h3>", unsafe_allow_html=True)
        
        st.markdown("**ğŸŸ¡ì›Œë“œí´ë¼ìš°ë“œ**")
        st.image("êµ­í˜ë°œì–¸ wc.png")
        
        st.markdown("**ğŸŸ¡ì–¸ì–´ë„¤íŠ¸ì›Œí¬**")
        st.write("ê³µì¶œí˜„ìˆ˜ì¹˜ 10 ì´ìƒì¸ ë‹¨ì–´ë§Œ í‘œì‹œë©ë‹ˆë‹¤")
        st.write("ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”")
        click = st.button("êµ­ë¯¼ì˜í˜ ì–¸ì–´ë„¤íŠ¸ì›Œí¬")
        if click : net(pp, 10)
        
        # st.markdown("* í† í”½ëª¨ë¸ë§")
        # if st.button('pyLDAvis ë³´ê¸°'):
        #     with st.spinner('Creating pyLDAvis Visualization ...'):
        #         dp_vis = pyLDAvis.gensim_models.prepare(r_a_ldamodel, r_a_corpus, r_a_dictionary, mds='mmds')
        #         py_lda_vis_html = pyLDAvis.prepared_data_to_html(dp_vis)
        
        st.markdown("**ğŸŸ¡ë„ë•ê¸°ë°˜ì‚¬ì „**")
        plot_2 = sns.barplot(x= moral_result.index, y=moral_result["êµ­í˜ë°œì–¸"], data = moral_result)
        plot_2.set_ylabel("ë‹¨ì–´ê°œìˆ˜")
        plot_2.figure.savefig('plot_2.png')
        plt.rcParams['font.family'] = 'NanumGothic'
        st.image("plot_2.png")
        
        selected_moral = st.selectbox('êµ­ë¯¼ì˜ í˜ ë„ë•ê¸°ë°˜ì„ íƒ', ["ë³´ì‚´í•Œ", "ê°€í•´", "ê³µì •", "ë¶€ì •", "ì¶©ì„±", "ë°°ë°˜", "ê¶Œìœ„", "ì „ë³µ", "ìˆœìˆ˜", "íƒ€ë½"])
        moral_dic = {"ë³´ì‚´í•Œ" : 0, "ê°€í•´" : 1, "ê³µì •": 2, "ë¶€ì •": 3 , "ì¶©ì„±":4 , "ë°°ë°˜":5 , "ê¶Œìœ„":6 , "ì „ë³µ":7 , "ìˆœìˆ˜":8 , "íƒ€ë½":9}
        moral_detail(pp_moral, moral_dic["{}".format(str(selected_moral))])        
        
    with col3 :
        st.markdown("<h3 style='text-align: center; background-color:gray'>í•œë™í›ˆ</h3>", unsafe_allow_html=True)
        st.markdown("**ğŸŸ¡ì›Œë“œí´ë¼ìš°ë“œ**")
        st.image("í•œë™í›ˆ ë°œì–¸ wc.png")
        
        st.markdown("**ğŸŸ¡ì–¸ì–´ë„¤íŠ¸ì›Œí¬**")
        st.write("ê³µì¶œí˜„ìˆ˜ì¹˜ 10 ì´ìƒì¸ ë‹¨ì–´ë§Œ í‘œì‹œë©ë‹ˆë‹¤")
        st.write("ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”")
        click = st.button("í•œë™í›ˆ ì–¸ì–´ë„¤íŠ¸ì›Œí¬")
        if click : net(han, 10)
        
        st.markdown("**ğŸŸ¡ë„ë•ê¸°ë°˜ì‚¬ì „**")
        plot_3 = sns.barplot(x= moral_result.index, y=moral_result["í•œë™í›ˆ"])
        plot_3.set_ylabel("ë‹¨ì–´ê°œìˆ˜")
        plot_3.figure.savefig('plot_3.png')
        plt.rcParams['font.family'] = 'NanumGothic'
        st.image("plot_3.png")
        
        selected_moral = st.selectbox('í•œë™í›ˆ ë„ë•ê¸°ë°˜ì„ íƒ', ["ë³´ì‚´í•Œ", "ê°€í•´", "ê³µì •", "ë¶€ì •", "ì¶©ì„±", "ë°°ë°˜", "ê¶Œìœ„", "ì „ë³µ", "ìˆœìˆ˜", "íƒ€ë½"])
        moral_dic = {"ë³´ì‚´í•Œ" : 0, "ê°€í•´" : 1, "ê³µì •": 2, "ë¶€ì •": 3 , "ì¶©ì„±":4 , "ë°°ë°˜":5 , "ê¶Œìœ„":6 , "ì „ë³µ":7 , "ìˆœìˆ˜":8 , "íƒ€ë½":9}
        moral_detail(han_moral, moral_dic["{}".format(str(selected_moral))])        


elif side == 'ì–¸ë¡ ë³´ë„' :
    st.header("ì–¸ë¡ ë³´ë„ ë°ì´í„°") 
    col1, col2 = st.columns(2)
    
    with col1 :
        st.markdown("<h3 style='text-align: center; background-color:red;'>ë³´ìˆ˜ì–¸ë¡  (ì¡°ì„ , ë™ì•„ì¼ë³´)</h3>", unsafe_allow_html=True)
        st.markdown(" ")
        st.markdown("**ğŸŸ¡ì›Œë“œí´ë¼ìš°ë“œ**")
        st.image("ë³´ìˆ˜ê¸°ì‚¬ wc.png")
        
        st.markdown("**ğŸŸ¡ì–¸ì–´ë„¤íŠ¸ì›Œí¬**")
        st.write("ê³µì¶œí˜„ìˆ˜ì¹˜ 30 ì´ìƒì¸ ë‹¨ì–´ë§Œ í‘œì‹œë©ë‹ˆë‹¤")
        st.write("ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”")
        click = st.button("ë³´ìˆ˜ì–¸ë¡  ì–¸ì–´ë„¤íŠ¸ì›Œí¬")
        if click : net(r_a, 30)
        
        
        st.markdown("**ğŸŸ¡ë„ë•ê¸°ë°˜ì‚¬ì „**")
        
        news_plot2 = sns.barplot(x= moral_result.index, y=moral_result["ë³´ìˆ˜ê¸°ì‚¬"], data = moral_result)
        news_plot2.set_ylabel("ë‹¨ì–´ê°œìˆ˜")
        news_plot2.figure.savefig('news_plot2.png')
        plt.rcParams['font.family'] = 'NanumGothic'
        st.image("news_plot2.png")
               
        selected_moral = st.selectbox('ë³´ìˆ˜ì–¸ë¡  ë„ë•ê¸°ë°˜ ì„ íƒ', ["ë³´ì‚´í•Œ", "ê°€í•´", "ê³µì •", "ë¶€ì •", "ì¶©ì„±", "ë°°ë°˜", "ê¶Œìœ„", "ì „ë³µ", "ìˆœìˆ˜", "íƒ€ë½"])
        moral_dic = {"ë³´ì‚´í•Œ" : 0, "ê°€í•´" : 1, "ê³µì •": 2, "ë¶€ì •": 3 , "ì¶©ì„±":4 , "ë°°ë°˜":5 , "ê¶Œìœ„":6 , "ì „ë³µ":7 , "ìˆœìˆ˜":8 , "íƒ€ë½":9}
        moral_detail(r_a_moral, moral_dic["{}".format(str(selected_moral))])

    
    with col2 :
        st.markdown("<h3 style='text-align: center; background-color:blue;'>ì§„ë³´ì–¸ë¡  (í•œê²¨ë ˆ,ê²½í–¥ì‹ ë¬¸)</h3>", unsafe_allow_html=True)
        st.markdown(" ")
        st.markdown("**ğŸŸ¡ì›Œë“œí´ë¼ìš°ë“œ**")
        st.image("ì§„ë³´ê¸°ì‚¬ wc.png")
        
        st.markdown("**ğŸŸ¡ì–¸ì–´ë„¤íŠ¸ì›Œí¬**")
        st.write("ê³µì¶œí˜„ìˆ˜ì¹˜ 30 ì´ìƒì¸ ë‹¨ì–´ë§Œ í‘œì‹œë©ë‹ˆë‹¤")
        st.write("ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”")
        click = st.button("ì§„ë³´ì–¸ë¡  ì–¸ì–´ë„¤íŠ¸ì›Œí¬")
        if click : net(l_a, 30)
        
        
        st.markdown("**ğŸŸ¡ë„ë•ê¸°ë°˜ì‚¬ì „**")
        
        news_plot = sns.barplot(x= moral_result.index, y=moral_result["ì§„ë³´ê¸°ì‚¬"], data = moral_result)
        news_plot.set_ylabel("ë‹¨ì–´ê°œìˆ˜")
        news_plot.figure.savefig('news_plot.png')
        plt.rcParams['font.family'] = 'NanumGothic'
        st.image("news_plot.png")
               
        selected_moral = st.selectbox('ì§„ë³´ì–¸ë¡  ë„ë•ê¸°ë°˜ ì„ íƒ', ["ë³´ì‚´í•Œ", "ê°€í•´", "ê³µì •", "ë¶€ì •", "ì¶©ì„±", "ë°°ë°˜", "ê¶Œìœ„", "ì „ë³µ", "ìˆœìˆ˜", "íƒ€ë½"])
        moral_dic = {"ë³´ì‚´í•Œ" : 0, "ê°€í•´" : 1, "ê³µì •": 2, "ë¶€ì •": 3 , "ì¶©ì„±":4 , "ë°°ë°˜":5 , "ê¶Œìœ„":6 , "ì „ë³µ":7 , "ìˆœìˆ˜":8 , "íƒ€ë½":9}
        moral_detail(l_a_moral, moral_dic["{}".format(str(selected_moral))])

    
elif side == 'ëŒ“ê¸€' :
    st.header("ëŒ“ê¸€ ë°ì´í„°") 
    col1, col2 = st.columns(2)
    
    with col1 :
        st.markdown("<h3 style='text-align: center; background-color:red;'>ë³´ìˆ˜ì–¸ë¡ ëŒ“ê¸€(ì¡°ì„ , ë™ì•„)</h3>", unsafe_allow_html=True)
        st.markdown(" ")
        st.markdown("**ğŸŸ¤ ì›Œë“œí´ë¼ìš°ë“œ**")
        st.image("ë³´ìˆ˜ëŒ“ê¸€ wc.png")
        
        st.markdown("**ğŸŸ¤ ì–¸ì–´ë„¤íŠ¸ì›Œí¬**")
        st.write("ê³µì¶œí˜„ìˆ˜ì¹˜ 10 ì´ìƒì¸ ë‹¨ì–´ë§Œ í‘œì‹œë©ë‹ˆë‹¤")
        st.write("ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”")
        click = st.button("ë³´ìˆ˜ì–¸ë¡ ëŒ“ê¸€ ì–¸ì–´ë„¤íŠ¸ì›Œí¬")
        if click : net(r_c, 10)
        
        
        st.markdown("**ğŸŸ¤ ë„ë•ê¸°ë°˜ì‚¬ì „**")
        
        com_plot = sns.barplot(x= moral_result.index, y=moral_result["ë³´ìˆ˜ëŒ“ê¸€"], data = moral_result)
        com_plot.set_ylabel("ë‹¨ì–´ê°œìˆ˜")
        com_plot.figure.savefig('com_plot.png')
        plt.rcParams['font.family'] = 'NanumGothic'
        st.image("com_plot.png")
               
        selected_moral = st.selectbox('ë³´ìˆ˜ì–¸ë¡  ë„ë•ê¸°ë°˜ ì„ íƒ', ["ë³´ì‚´í•Œ", "ê°€í•´", "ê³µì •", "ë¶€ì •", "ì¶©ì„±", "ë°°ë°˜", "ê¶Œìœ„", "ì „ë³µ", "ìˆœìˆ˜", "íƒ€ë½"])
        moral_dic = {"ë³´ì‚´í•Œ" : 0, "ê°€í•´" : 1, "ê³µì •": 2, "ë¶€ì •": 3 , "ì¶©ì„±":4 , "ë°°ë°˜":5 , "ê¶Œìœ„":6 , "ì „ë³µ":7 , "ìˆœìˆ˜":8 , "íƒ€ë½":9}
        moral_detail(r_c_moral, moral_dic["{}".format(str(selected_moral))])

    
    with col2 :
        st.markdown("<h3 style='text-align: center; background-color:blue;'>ì§„ë³´ì–¸ë¡ ëŒ“ê¸€(í•œê²¨ë ˆ,ê²½í–¥)</h3>", unsafe_allow_html=True)
        st.markdown(" ")
        st.markdown("**ğŸŸ¤ ì›Œë“œí´ë¼ìš°ë“œ**")
        st.image("ì§„ë³´ëŒ“ê¸€ wc.png")
        
        st.markdown("**ğŸŸ¤ ì–¸ì–´ë„¤íŠ¸ì›Œí¬**")
        st.write("ê³µì¶œí˜„ìˆ˜ì¹˜ 10 ì´ìƒì¸ ë‹¨ì–´ë§Œ í‘œì‹œë©ë‹ˆë‹¤")
        st.write("ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”")
        click = st.button("ì§„ë³´ì–¸ë¡ ëŒ“ê¸€ ì–¸ì–´ë„¤íŠ¸ì›Œí¬")
        if click : net(r_a, 10)
        
        
        st.markdown("**ğŸŸ¤ ë„ë•ê¸°ë°˜ì‚¬ì „**")
        
        com_plot2 = sns.barplot(x= moral_result.index, y=moral_result["ì§„ë³´ëŒ“ê¸€"], data = moral_result)
        com_plot2.set_ylabel("ë‹¨ì–´ê°œìˆ˜")
        com_plot2.figure.savefig('com_plot2.png')
        plt.rcParams['font.family'] = 'NanumGothic'
        st.image("com_plot2.png")
               
        selected_moral = st.selectbox('ì§„ë³´ì–¸ë¡  ë„ë•ê¸°ë°˜ ì„ íƒ', ["ë³´ì‚´í•Œ", "ê°€í•´", "ê³µì •", "ë¶€ì •", "ì¶©ì„±", "ë°°ë°˜", "ê¶Œìœ„", "ì „ë³µ", "ìˆœìˆ˜", "íƒ€ë½"])
        moral_dic = {"ë³´ì‚´í•Œ" : 0, "ê°€í•´" : 1, "ê³µì •": 2, "ë¶€ì •": 3 , "ì¶©ì„±":4 , "ë°°ë°˜":5 , "ê¶Œìœ„":6 , "ì „ë³µ":7 , "ìˆœìˆ˜":8 , "íƒ€ë½":9}
        moral_detail(l_c_moral, moral_dic["{}".format(str(selected_moral))])    